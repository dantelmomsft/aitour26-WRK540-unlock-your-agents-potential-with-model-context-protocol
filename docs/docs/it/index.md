# Sblocca il Potenziale del Tuo Agente con Model Context Protocol e PostgreSQL

## Un workshop interattivo di 50 minuti

Immagina di essere un manager delle vendite presso Zava, un'azienda retail DIY con negozi in tutto lo Stato di Washington e una presenza online in crescita. Ti specializzi in attrezzature per esterni, strumenti per il miglioramento della casa e forniture DIY.

Devi analizzare i dati di vendita per trovare tendenze, comprendere le preferenze dei clienti e prendere decisioni aziendali informate. Per aiutarti, Zava ha sviluppato un agente conversazionale che può rispondere a domande sui tuoi dati di vendita.

![Agente di Analisi Vendite Zava](media/persona.png)

## Cosa imparerai nel workshop

Impara a costruire un agente AI che analizza dati di vendita, risponde a domande sui prodotti e aiuta i clienti a trovare prodotti usando la ricerca per immagini. Argomenti chiave:

1. **Servizio Agente Azure AI Foundry**: Costruisci e distribuisci agenti AI con strumenti integrati e osservabilità.  
2. **Model Context Protocol (MCP)**: Connetti LLM a strumenti esterni, dati e sistemi per funzionalità migliorate.  
3. **Azure AI Foundry**: Costruisci e distribuisci rapidamente agenti AI con strumenti integrati e osservabilità.

### Stai iniziando ora il tuo percorso con gli Agenti AI?

Se sei nuovo agli agenti AI, inizia con il workshop [Build your code-first agent with Azure AI Foundry](https://aka.ms/aitour/WRK552){:target="_blank"}. Imparerai a costruire un agente code-first usando Azure AI Foundry, integrando LLM con database, documenti e ricerca Bing — una base solida per agenti più avanzati come l'Agente Zava.

## Cos'è un Agente AI Alimentato da LLM?

Un Agente AI alimentato da Large Language Model (LLM) è un software semi-autonomo progettato per raggiungere un obiettivo dato senza richiedere passaggi o processi predefiniti. Piuttosto che seguire istruzioni esplicitamente programmate, l'agente determina come portare a termine un compito usando istruzioni e contesto.

Per esempio, se un utente chiede, "**Mostra le vendite totali per ogni negozio come grafico a torta**", l'app non si basa su logica predefinita per questa richiesta. Invece, il LLM interpreta la richiesta, gestisce il flusso della conversazione e il contesto, e orchestra le azioni necessarie per produrre il grafico a torta delle vendite dei negozi.

A differenza delle applicazioni tradizionali, dove gli sviluppatori definiscono la logica e i flussi di lavoro per supportare i processi aziendali, gli Agenti AI spostano questa responsabilità al LLM. In questi sistemi, il prompt engineering, istruzioni chiare e lo sviluppo di strumenti sono critici per garantire che l'app funzioni come previsto.

## Introduzione ad Azure AI Foundry

[Azure AI Foundry](https://azure.microsoft.com/products/ai-foundry/){:target="_blank"} è la piattaforma sicura e flessibile di Microsoft per progettare, personalizzare e gestire app e agenti AI. Tutto—modelli, agenti, strumenti e osservabilità—vive dietro un singolo portale, SDK ed endpoint REST, così puoi distribuire su cloud o edge con governance e controlli dei costi in atto dal primo giorno.

![Architettura Azure AI Foundry](media/azure-ai-foundry.png)

*Tradotto utilizzando GitHub Copilot e GPT-4o.*
