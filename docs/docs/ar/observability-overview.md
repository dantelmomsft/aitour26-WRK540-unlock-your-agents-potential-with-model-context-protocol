تضمن قابلية المراقبة أن أنظمة الذكاء الاصطناعي موثوقة وآمنة وعالية الجودة من خلال تمكين المراقبة والتقييم المستمر. بالنسبة للقادة التقنيين والمطورين، إنها مفتاح بناء الثقة والحفاظ على الأداء في تطبيقات الذكاء الاصطناعي التوليدي.

مع Azure AI Foundry، تعني قابلية المراقبة:

- استخدام المقيّمين لقياس الجودة والأمان والموثوقية في كل مرحلة—من اختيار النموذج إلى الإنتاج.
- تقييم النماذج والتطبيقات قبل النشر، ومراقبتها في الوقت الفعلي بعد الإطلاق.
- تتبع المقاييس مثل الصلة والأساس والأمان لتحديد ومعالجة المخاطر بسرعة.
- الاستفادة من لوحات المعلومات المتكاملة وAzure Monitor للحصول على رؤى قابلة للتنفيذ.

تساعد ممارسات قابلية المراقبة الأفضل المؤسسات على تقديم ذكاء اصطناعي جدير بالثقة وتقليل المخاطر وتحقيق الأهداف التجارية.

لمزيد من التفاصيل حول قابلية المراقبة، راجع [نظرة عامة على قابلية مراقبة Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/observability){:target="_blank"}.

*Translated using GitHub Copilot and GPT-4o.*
