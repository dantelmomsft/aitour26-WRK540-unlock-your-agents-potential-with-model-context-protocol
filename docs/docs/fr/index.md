# Débloquez le Potentiel de Votre Agent avec Model Context Protocol et PostgreSQL

## Un atelier interactif de 50 minutes

Imaginez que vous êtes un directeur des ventes chez Zava, une entreprise de bricolage de détail avec des magasins à travers l'État de Washington et une présence en ligne croissante. Vous vous spécialisez dans l'équipement d'extérieur, les outils d'amélioration résidentielle et les fournitures de bricolage.

Vous devez analyser les données de vente pour trouver des tendances, comprendre les préférences des clients et prendre des décisions commerciales éclairées. Pour vous aider, Zava a développé un agent conversationnel qui peut répondre aux questions sur vos données de vente.

![Agent d'Analyse des Ventes Zava](media/persona.png)

## Ce que vous apprendrez dans l'atelier

Apprenez à construire un agent IA qui analyse les données de vente, répond aux questions sur les produits et aide les clients à trouver des produits en utilisant la recherche d'images. Sujets clés :

1. **Service d'Agent Azure AI Foundry** : Construire et déployer des agents IA avec des outils intégrés et l'observabilité.  
2. **Model Context Protocol (MCP)** : Connecter les LLM aux outils, données et systèmes externes pour une fonctionnalité améliorée.  
3. **Azure AI Foundry** : Construire et déployer rapidement des agents IA avec des outils intégrés et l'observabilité.

### Vous commencez tout juste votre parcours avec les Agents IA ?

Si vous êtes nouveau dans les agents IA, commencez par l'atelier [Construisez votre agent code-first avec Azure AI Foundry](https://aka.ms/aitour/WRK552){:target="_blank"}. Vous apprendrez à construire un agent code-first en utilisant Azure AI Foundry, intégrant les LLM avec des bases de données, des documents et la recherche Bing — une base solide pour des agents plus avancés comme l'Agent Zava.

## Qu'est-ce qu'un Agent IA Alimenté par LLM ?

Un Agent IA alimenté par un Grand Modèle de Langage (LLM) est un logiciel semi-autonome conçu pour atteindre un objectif donné sans nécessiter d'étapes ou de processus prédéfinis. Plutôt que de suivre des instructions explicitement programmées, l'agent détermine comment accomplir une tâche en utilisant des instructions et du contexte.

Par exemple, si un utilisateur demande, "**Montrez les ventes totales pour chaque magasin sous forme de graphique en secteurs**", l'application ne s'appuie pas sur une logique prédéfinie pour cette demande. Au lieu de cela, le LLM interprète la demande, gère le flux de conversation et le contexte, et orchestre les actions nécessaires pour produire le graphique en secteurs des ventes de magasin.

Contrairement aux applications traditionnelles, où les développeurs définissent la logique et les flux de travail pour soutenir les processus métier, les Agents IA transfèrent cette responsabilité au LLM. Dans ces systèmes, l'ingénierie des prompts, des instructions claires et le développement d'outils sont critiques pour s'assurer que l'application fonctionne comme prévu.

## Introduction à Azure AI Foundry

[Azure AI Foundry](https://azure.microsoft.com/products/ai-foundry/){:target="_blank"} est la plateforme sécurisée et flexible de Microsoft pour concevoir, personnaliser et gérer les applications et agents IA. Tout—modèles, agents, outils et observabilité—vit derrière un portail unique, SDK et point de terminaison REST, afin que vous puissiez déployer vers le cloud ou la périphérie avec la gouvernance et les contrôles de coûts en place dès le premier jour.

![Architecture Azure AI Foundry](media/azure-ai-foundry.png)

*Traduit en utilisant GitHub Copilot et GPT-4o.*
