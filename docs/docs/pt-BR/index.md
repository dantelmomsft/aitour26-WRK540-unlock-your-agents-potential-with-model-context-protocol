# Desbloqueie o Potencial do seu Agente com Protocolo de Contexto de Modelo e PostgreSQL

## Um workshop interativo de 50 minutos

Imagine que você é um gerente de vendas na Zava, uma empresa de varejo DIY com lojas em todo o Estado de Washington e uma presença online crescente. Você se especializa em equipamentos para atividades ao ar livre, ferramentas para melhoria residencial e suprimentos DIY.

Você precisa analisar dados de vendas para encontrar tendências, entender preferências do cliente e tomar decisões comerciais informadas. Para ajudá-lo, a Zava desenvolveu um agente conversacional que pode responder perguntas sobre seus dados de vendas.

![Agente de Análise de Vendas Zava](media/persona.png)

## O que você aprenderá no workshop

Aprenda a construir um agente de IA que analisa dados de vendas, responde perguntas sobre produtos e ajuda clientes a encontrar produtos usando busca por imagem. Tópicos principais:

1. **Serviço de Agente Azure AI Foundry**: Construa e implante agentes de IA com ferramentas integradas e observabilidade.  
2. **Protocolo de Contexto de Modelo (MCP)**: Conecte LLMs a ferramentas, dados e sistemas externos para funcionalidade aprimorada.  
3. **Azure AI Foundry**: Construa e implante rapidamente agentes de IA com ferramentas integradas e observabilidade.

### Apenas começando sua jornada com Agentes de IA?

Se você é novo em agentes de IA, comece com o workshop [Build your code-first agent with Azure AI Foundry](https://aka.ms/aitour/WRK552){:target="_blank"}. Você aprenderá a construir um agente code-first usando Azure AI Foundry, integrando LLMs com bancos de dados, documentos e busca Bing — uma base sólida para agentes mais avançados como o Agente Zava.

## O que é um Agente de IA Alimentado por LLM?

Um Agente de IA alimentado por Modelo de Linguagem Grande (LLM) é um software semiautônomo projetado para alcançar um objetivo específico sem exigir etapas ou processos predefinidos. Em vez de seguir instruções explicitamente programadas, o agente determina como realizar uma tarefa usando instruções e contexto.

Por exemplo, se um usuário perguntar, "**Mostre as vendas totais para cada loja como um gráfico de pizza**", a aplicação não depende de lógica predefinida para esta solicitação. Em vez disso, o LLM interpreta a solicitação, gerencia o fluxo de conversa e contexto, e orquestra as ações necessárias para produzir o gráfico de pizza das vendas da loja.

Diferentemente de aplicações tradicionais, onde desenvolvedores definem a lógica e fluxos de trabalho para suportar processos comerciais, Agentes de IA transferem essa responsabilidade para o LLM. Nestes sistemas, engenharia de prompt, instruções claras e desenvolvimento de ferramentas são críticos para garantir que a aplicação funcione conforme pretendido.

## Introdução ao Azure AI Foundry

[Azure AI Foundry](https://azure.microsoft.com/products/ai-foundry/){:target="_blank"} é a plataforma segura e flexível da Microsoft para projetar, personalizar e gerenciar aplicações e agentes de IA. Tudo—modelos, agentes, ferramentas e observabilidade—fica atrás de um único portal, SDK e endpoint REST, para que você possa implantar na nuvem ou edge com governança e controles de custo estabelecidos desde o primeiro dia.

![Arquitetura Azure AI Foundry](media/azure-ai-foundry.png)

*Traduzido usando GitHub Copilot e GPT-4o.*
